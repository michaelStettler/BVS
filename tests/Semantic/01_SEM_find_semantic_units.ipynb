{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Find semantic units of interest (IoU) by running the implementation of the Semantic pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.load_config import load_config\n",
    "from utils.extraction_model import load_extraction_model\n",
    "\n",
    "from utils.Semantic.load_coco_semantic_annotations import load_coco_semantic_annotations\n",
    "from utils.Semantic.load_coco_semantic_annotations import get_coco_cat_ids\n",
    "from utils.Semantic.find_semantic_units import find_semantic_units\n",
    "from utils.Semantic.find_semantic_units import get_IoU_per_category"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# define configuration\n",
    "config_path = 'SEM_t01_find_semantic_units_m0001.json'\n",
    "\n",
    "# load config\n",
    "config = load_config(config_path, path='../../configs/Semantic')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Metal device set to: Apple M1 Pro\n",
      " Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 11:06:55.316275: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-13 11:06:55.316484: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] size_ft (56, 56)\n",
      "[LOAD] Model loaded\n"
     ]
    }
   ],
   "source": [
    "# load CNN model to compute IoU on it\n",
    "model = load_extraction_model(config, input_shape=tuple(config[\"input_shape\"]))\n",
    "model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(config['v4_layer']).output)\n",
    "size_ft = tuple(np.shape(model.output)[1:3])\n",
    "print(\"[LOAD] size_ft\", size_ft)\n",
    "print(\"[LOAD] Model loaded\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "semantic_data = load_coco_semantic_annotations(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find semantic units"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IoU] num classes 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IoU] layer 0 name block1_conv1:\n",
      "2/2 [==============================] - 0s 62ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 11:06:59.127081: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-13 11:06:59.158361: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IoU] shape preds (35, 224, 224, 64)\n",
      "[IoU] num units 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:53<07:05, 53.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_units\n",
      "[ 0 17  0  0 36 42  5 33  0 42  0 37  5  0  0 44  0 12 37 44  5 34  0]\n",
      "[IoU] layer 1 name block1_conv2:\n",
      "2/2 [==============================] - 0s 79ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 11:07:52.285056: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IoU] shape preds (35, 224, 224, 64)\n",
      "[IoU] num units 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [01:46<06:11, 53.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_units\n",
      "[ 0 12  0  0 42 46 14 54  0 48  0 43  2  0  0 51  0 10 56 51  2 38  0]\n",
      "[IoU] layer 2 name block1_pool:\n",
      "2/2 [==============================] - 0s 79ms/step\n",
      "[IoU] shape preds (35, 112, 112, 64)\n",
      "[IoU] num units 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 11:08:45.229686: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      " 33%|███▎      | 3/9 [02:36<05:11, 51.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_units\n",
      "[ 0 10  0  0 42 40 18 56  0 47  3 43  9  0  0 51  0  9 56 52  4 40  0]\n",
      "[IoU] layer 3 name block2_conv1:\n",
      "2/2 [==============================] - 0s 129ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 11:09:35.923448: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IoU] shape preds (35, 112, 112, 128)\n",
      "[IoU] num units 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [04:51<07:04, 84.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_units\n",
      "[  0  29   0   0  86  94  22 108   0 107   1  96  18   0   0 109   0  26\n",
      " 110 109   4  91   0]\n",
      "[IoU] layer 4 name block2_conv2:\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x29ca5de10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/2 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 11:11:51.108822: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 185ms/step\n",
      "[IoU] shape preds (35, 112, 112, 128)\n",
      "[IoU] num units 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [07:05<06:49, 102.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_units\n",
      "[  0  32   0   0 109 117  36 116   0 125   0 112  14   0   0 126   0  21\n",
      " 122 126   5  80   0]\n",
      "[IoU] layer 5 name block2_pool:\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x29ca5e5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 11:14:04.431735: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 126ms/step\n",
      "[IoU] shape preds (35, 56, 56, 128)\n",
      "[IoU] num units 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [09:16<05:36, 112.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_units\n",
      "[  0  40   0   0 107 107  49 120   0 122   4 112  31   1   0 124   0  36\n",
      " 124 124  17  94   0]\n",
      "[IoU] layer 6 name block3_conv1:\n",
      "1/2 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 11:16:15.775449: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 142ms/step\n",
      "[IoU] shape preds (35, 56, 56, 256)\n",
      "[IoU] num units 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [13:51<05:30, 165.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_units\n",
      "[  0 101   0   0 205 214  66 234   0 237   4 213  38   3   0 247   0  52\n",
      " 239 249  24 179   0]\n",
      "[IoU] layer 7 name block3_conv2:\n",
      "1/2 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 11:20:50.946754: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 666ms/step\n",
      "[IoU] shape preds (35, 56, 56, 256)\n",
      "[IoU] num units 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [18:26<03:20, 200.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_units\n",
      "[  0 115   0   0 213 208  88 247   0 241   3 224  39   0   0 256   0  50\n",
      " 252 256  19 200   0]\n",
      "[IoU] layer 8 name block3_conv3:\n",
      "1/2 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 11:25:26.049627: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 663ms/step\n",
      "[IoU] shape preds (35, 56, 56, 256)\n",
      "[IoU] num units 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [23:05<00:00, 153.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_units\n",
      "[  0 124   0   0 192 213  67 253   0 234   7 201  34   2   0 251   0  61\n",
      " 255 256  16 212   0]\n",
      "[IoU] finished computing IoU\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get all idx list for each category\n",
    "sem_idx_list = find_semantic_units(model, semantic_data, config, verbose=1)\n",
    "\n",
    "# get category IDs of interest (transform semantic units name to category id of COCO)\n",
    "cat_ids = get_coco_cat_ids(config, config['semantic_units'], to_numpy=True)\n",
    "\n",
    "# get CNN feature map indexes (gather all feature map index across the whole architecture for each category of interest)\n",
    "cat_feature_map_indexes = get_IoU_per_category(sem_idx_list, cat_ids)\n",
    "\n",
    "print(\"-- finished computing semantic units --\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Print Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_10 (eyes) indices found: \n",
      "[161 114 229  82  19 125 136]\n",
      "category_13 (eyebrow) indices found: \n",
      "[ 68 125]\n",
      "category_17 (nose) indices found: \n",
      "[101  52 172 210 167 216  85 102 232   4  77 162   1  33 208  29  30  93\n",
      "  59 104  23 133 161 115  19  81  74  97 148 120 221   9 103 149 246 150\n",
      " 137 226  34 233 229  54  31 242  37 155 171 255 235 124 224 196 227  27\n",
      " 241 107 228 211 243 166  20]\n",
      "category_20 (lips) indices found: \n",
      "[235 203  68 125   3 181 197   2  87 240   6  95  60 157 227 111]\n"
     ]
    }
   ],
   "source": [
    "categories = [\"eyes\", \"eyebrow\", \"nose\", \"lips\"]  # this is taken from Hasty.ai labelling\n",
    "for i, cat in enumerate(cat_feature_map_indexes):\n",
    "    print(\"{} ({}) indices found: \".format(cat, categories[i]))\n",
    "    print(cat_feature_map_indexes[cat][config['v4_layer']]['indexes'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}